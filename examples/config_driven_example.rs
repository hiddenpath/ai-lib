use ai_lib::types::common::Content;
use ai_lib::{AiClient, ChatCompletionRequest, Message, Provider, Role};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ é…ç½®é©±åŠ¨çš„AI-libç¤ºä¾‹");
    println!("========================");

    // æ¼”ç¤ºé…ç½®é©±åŠ¨çš„ä¼˜åŠ¿ï¼šè½»æ¾åˆ‡æ¢æä¾›å•†
    let providers = vec![
        (Provider::Groq, "Groq"),
        (Provider::OpenAI, "OpenAI"),
        (Provider::DeepSeek, "DeepSeek"),
    ];

    for (provider, name) in providers {
        println!("\nğŸ“¡ æµ‹è¯•æä¾›å•†: {}", name);

        // åˆ›å»ºå®¢æˆ·ç«¯ - åªéœ€æ”¹å˜æšä¸¾å€¼
        let client = AiClient::new(provider)?;
        println!("âœ… å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {:?}", client.current_provider());

        // è·å–æ¨¡å‹åˆ—è¡¨
        match client.list_models().await {
            Ok(models) => println!("ğŸ“‹ å¯ç”¨æ¨¡å‹: {:?}", models),
            Err(e) => println!("âš ï¸  è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {}", e),
        }

        // åˆ›å»ºæµ‹è¯•è¯·æ±‚
        let request = ChatCompletionRequest::new(
            "test-model".to_string(),
            vec![Message {
                role: Role::User,
                content: Content::Text("Hello from ai-lib!".to_string()),
                function_call: None,
            }],
        );

        println!("ğŸ“¤ è¯·æ±‚å·²å‡†å¤‡ï¼Œæ¨¡å‹: {}", request.model);
        println!("   (éœ€è¦è®¾ç½®å¯¹åº”çš„API_KEYç¯å¢ƒå˜é‡æ‰èƒ½å®é™…è°ƒç”¨)");
    }

    println!("\nğŸ¯ é…ç½®é©±åŠ¨çš„æ ¸å¿ƒä¼˜åŠ¿:");
    println!("   â€¢ é›¶ä»£ç åˆ‡æ¢: åªéœ€æ”¹å˜Provideræšä¸¾å€¼");
    println!("   â€¢ ç»Ÿä¸€æ¥å£: æ‰€æœ‰æä¾›å•†ä½¿ç”¨ç›¸åŒçš„API");
    println!("   â€¢ å¿«é€Ÿæ‰©å±•: æ–°å¢å…¼å®¹æä¾›å•†åªéœ€æ·»åŠ é…ç½®");

    Ok(())
}
