use ai_lib::{AiClient, Provider, ChatCompletionRequest, Message, Role};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ AI-lib Basic Usage Example");
    println!("================================");
    
    // åˆ‡æ¢æ¨¡å‹æä¾›å•†ï¼Œåªéœ€æ›´æ”¹ Provider çš„å€¼
    let client = AiClient::new(Provider::Groq)?;
    println!("âœ… Created client with provider: {:?}", client.current_provider());
    
    // è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    let models = client.list_models().await?;
    println!("ğŸ“‹ Available models: {:?}", models);
    
    // åˆ›å»ºèŠå¤©è¯·æ±‚
    let request = ChatCompletionRequest::new(
        "llama3-8b-8192".to_string(),
        vec![Message {
            role: Role::User,
            content: "Hello! Please introduce yourself briefly.".to_string(),
        }],
    ).with_temperature(0.7)
     .with_max_tokens(100);
    
    println!("ğŸ“¤ Sending request to model: {}", request.model);
    
    // å‘é€è¯·æ±‚
    let response = client.chat_completion(request).await?;
    
    println!("ğŸ“¥ Received response:");
    println!("   ID: {}", response.id);
    println!("   Model: {}", response.model);
    println!("   Content: {}", response.choices[0].message.content);
    println!("   Usage: {} tokens", response.usage.total_tokens);
    
    Ok(())
}
