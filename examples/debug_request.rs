use ai_lib::types::common::Content;
use ai_lib::{AiClient, ChatCompletionRequest, Message, Provider, Role};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ” è°ƒè¯•è¯·æ±‚æ ¼å¼");
    println!("===============");

    // åˆ›å»ºæµ‹è¯•è¯·æ±‚
    let request = ChatCompletionRequest::new(
        "gpt-3.5-turbo".to_string(),
        vec![Message {
            role: Role::User,
            content: Content::Text("Hello!".to_string()),
            function_call: None,
        }],
    )
    .with_max_tokens(10);

    println!("ğŸ“¤ åŸå§‹è¯·æ±‚:");
    println!("   æ¨¡å‹: {}", request.model);
    println!("   æ¶ˆæ¯æ•°é‡: {}", request.messages.len());
    println!(
        "   æ¶ˆæ¯[0]: {:?} - {}",
        request.messages[0].role,
        request.messages[0].content.as_text()
    );
    println!("   max_tokens: {:?}", request.max_tokens);

    // æµ‹è¯•OpenAI
    println!("\nğŸ¤– æµ‹è¯•OpenAI...");
    match AiClient::new(Provider::OpenAI) {
        Ok(client) => {
            match client.chat_completion(request.clone()).await {
                Ok(response) => {
                    println!("âœ… æˆåŠŸ!");
                    println!("   å“åº”: {}", response.choices[0].message.content.as_text());
                }
                Err(e) => {
                    println!("âŒ å¤±è´¥: {}", e);

                    // å¦‚æœæ˜¯400é”™è¯¯ï¼Œè¯´æ˜è¯·æ±‚æ ¼å¼æœ‰é—®é¢˜
                    if e.to_string().contains("400") {
                        println!("   è¿™é€šå¸¸è¡¨ç¤ºè¯·æ±‚æ ¼å¼ä¸æ­£ç¡®");
                        println!("   è®©æˆ‘ä»¬æ£€æŸ¥è¯·æ±‚æ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ...");
                    }
                }
            }
        }
        Err(e) => println!("âŒ å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {}", e),
    }

    Ok(())
}
