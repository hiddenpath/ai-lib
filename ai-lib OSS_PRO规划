ai-lib库项目 OSS/PRO 规划
让我查看 ai-lib、ai-lib-pro 和 ailib.info 项目中关于 OSS/PRO 规划的相关文档。

[12 tools called]

现在我已经全面审查了 ai-lib、ai-lib-pro 和 ailib.info 的架构文档。基于项目的 OSS/PRO 分层规划，我来给出系统性的分析和建议。

---

## 深入分析：基于 OSS/PRO 双轨制的热更新策略

### 现有规划的关键发现

从 `model_resolver_pro_plan.md` 中可以看到，项目已经规划了清晰的里程碑：

```1:46:d:\rustapp\ai-lib-pro\docs\model_resolver_pro_plan.md
# Model Resolver – PRO Stage Plan
...
### M1 – Externalized Model Registry
- Define a TOML/JSON schema that lists provider defaults, fallbacks, and feature
  tags (reasoning, vision, streaming, price tier).
- Implement a loader + hot-reload mechanism in ai-lib-pro that can ingest this
  registry from disk, HTTP, or config backends (Consul, etcd).
...
```

结合 `ADR-002-feature-flags.md` 的渐进式复杂度原则：

```11:34:d:\rustapp\ai-lib\docs\architecture\ADR-002-feature-flags.md
## Decision
Implement **progressive complexity** via Cargo feature flags:

### Core Features (Always Available)
- Basic chat completion
- Provider abstraction
- Error handling
- Streaming support

### Optional Features (Feature-Gated)
- `interceptors` - Retry, timeout, circuit breaker
- `unified_sse` - Common SSE parser
- `unified_transport` - Shared HTTP client
- `cost_metrics` - Basic cost tracking
- `routing_mvp` - Model selection strategies
- `observability` - Tracing interfaces
- `config_hot_reload` - Dynamic configuration
```

---

## 一、模型分类体系设计（符合 OSS/PRO 分层）

### 推荐的分类方案

| 分类维度 | OSS 层级 | PRO 层级 |
|----------|----------|----------|
| **主类型 (Primary Type)** | 静态枚举，编译时确定 | 动态标签，运行时可扩展 |
| **能力标签 (Capabilities)** | bitflags 核心能力 | 扩展能力 + 自定义标签 |
| **性能分级 (Performance)** | 简单三档 (Fast/Balanced/Quality) | 量化指标 + SLO |
| **定价信息 (Pricing)** | 静态参考值 | 实时更新 + 多币种 |

### OSS 层：静态核心分类

```rust
// ai-lib/src/model/types.rs (编译时确定)

/// 主类型 - 互斥，每个模型只属于一个主类型
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum ModelPrimaryType {
    /// 通用对话 (gpt-4o, claude-3-sonnet, qwen-turbo)
    Chat,
    /// 推理/思考 (o1, deepseek-reasoner, qwq-32b)
    Reasoning,
    /// 代码专精 (codestral, deepseek-coder)
    Coding,
    /// 多模态 (gpt-4o-vision, gemini-1.5-pro)
    Multimodal,
    /// 嵌入向量 (text-embedding-3-small)
    Embedding,
}

/// 核心能力位图 - 可组合
bitflags::bitflags! {
    #[derive(Debug, Clone, Copy, Serialize, Deserialize)]
    pub struct ModelCapabilities: u32 {
        // 输入模态
        const TEXT_INPUT    = 1 << 0;
        const IMAGE_INPUT   = 1 << 1;
        const AUDIO_INPUT   = 1 << 2;
        const VIDEO_INPUT   = 1 << 3;
        
        // 输出模态
        const TEXT_OUTPUT   = 1 << 4;
        const IMAGE_OUTPUT  = 1 << 5;
        const AUDIO_OUTPUT  = 1 << 6;
        
        // 高级特性
        const STREAMING     = 1 << 8;
        const FUNCTION_CALL = 1 << 9;
        const TOOL_USE      = 1 << 10;
        const JSON_MODE     = 1 << 11;
        
        // 推理特性
        const REASONING_TRACE = 1 << 12;  // 输出思考过程
        const LONG_CONTEXT    = 1 << 13;  // >32K context
        
        // 便捷组合
        const MULTIMODAL_VISION = Self::TEXT_INPUT.bits() | Self::IMAGE_INPUT.bits() | Self::TEXT_OUTPUT.bits();
        const CHAT_STANDARD = Self::TEXT_INPUT.bits() | Self::TEXT_OUTPUT.bits() | Self::STREAMING.bits();
    }
}

/// 性能分级 (OSS 简单版)
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum PerformanceTier {
    Fast,      // 低延迟，适合实时交互
    Balanced,  // 平衡
    Quality,   // 高质量，可能较慢
}

/// 模型状态
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum ModelStatus {
    Active,     // 正常可用
    Preview,    // 预览版
    Deprecated, // 已废弃
    Legacy,     // 旧版仍可用
}
```

### PRO 层：动态扩展

```rust
// ai-lib-pro/src/model_registry/extended.rs

/// PRO 扩展能力标签 (动态，可热更新)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExtendedCapabilities {
    /// 基础能力 (复用 OSS)
    pub core: ModelCapabilities,
    
    /// 扩展标签 (动态可配)
    pub tags: HashSet<String>,  // ["medical", "legal", "chinese-optimized"]
    
    /// 性能 SLO
    pub performance_slo: Option<PerformanceSLO>,
    
    /// 实时定价 (多币种)
    pub pricing: Option<DynamicPricing>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceSLO {
    pub p50_latency_ms: u32,
    pub p95_latency_ms: u32,
    pub p99_latency_ms: u32,
    pub availability_percent: f32,  // 99.9
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DynamicPricing {
    pub input_per_million: f64,
    pub output_per_million: f64,
    pub currency: String,
    pub effective_date: String,
    pub source: PricingSource,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PricingSource {
    Static,           // 内置静态值
    ConfigFile,       // 本地配置文件
    RemoteRegistry,   // 远程注册中心
    ProviderApi,      // 直接从 Provider API 获取
}
```

---

## 二、数据文件更新策略（OSS/PRO 分层）

### 架构分层图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           数据更新策略分层                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                        ai-lib (OSS)                                   │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                   │   │
│  │  │ 编译时嵌入   │  │ 环境变量覆盖 │  │ 本地文件覆盖 │                   │   │
│  │  │ (include!)  │→ │ (runtime)   │→ │ (runtime)   │                   │   │
│  │  │             │  │             │  │             │                   │   │
│  │  │ • providers │  │ • API Keys  │  │ • 自定义模型 │                   │   │
│  │  │ • models    │  │ • Base URLs │  │ • 价格覆盖   │                   │   │
│  │  │ • defaults  │  │ • Proxies   │  │ • 新增Provider│                   │   │
│  │  └─────────────┘  └─────────────┘  └─────────────┘                   │   │
│  │       ↑ 无网络依赖    ↑ 部署时配置    ↑ 用户可选                        │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                    │                                         │
│                                    │ (feature gate: config_hot_reload)       │
│                                    ↓                                         │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                        ai-lib-pro (Enterprise)                        │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                   │   │
│  │  │ 文件热更新   │  │ 远程配置中心 │  │ Provider API │                   │   │
│  │  │ (polling)   │→ │ (Consul/etcd)│→ │ (live sync)  │                   │   │
│  │  │             │  │             │  │             │                   │   │
│  │  │ • 定价变动  │  │ • 多租户策略 │  │ • 模型列表   │                   │   │
│  │  │ • 新模型上线 │  │ • 审批工作流 │  │ • 实时可用性 │                   │   │
│  │  │ • 能力变更  │  │ • 配额控制   │  │ • 健康状态   │                   │   │
│  │  └─────────────┘  └─────────────┘  └─────────────┘                   │   │
│  │       ↑ 零停机      ↑ 企业集成        ↑ 实时同步                        │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### OSS 层实现

```rust
// ai-lib/src/registry/mod.rs

/// 模型注册表 (OSS 版本)
pub struct ModelRegistry {
    /// Provider 配置
    providers: HashMap<String, ProviderDefinition>,
    /// 模型定义
    models: HashMap<String, ModelDefinition>,
    /// 数据版本
    version: String,
    /// 加载来源
    source: RegistrySource,
}

#[derive(Debug, Clone)]
pub enum RegistrySource {
    Embedded,    // 编译时嵌入
    LocalFile,   // 本地文件覆盖
    Custom,      // 用户自定义
}

impl ModelRegistry {
    /// 构建加载链 (OSS: 无网络依赖)
    pub fn load() -> Result<Self, RegistryError> {
        let mut registry = Self::default();
        
        // 1. 加载编译时嵌入的默认配置 (保底)
        registry.load_embedded()?;
        
        // 2. 检查本地数据目录覆盖 (~/.ai-lib/data/)
        if let Some(local_dir) = Self::find_local_data_dir() {
            registry.merge_from_dir(&local_dir)?;
        }
        
        // 3. 检查工作目录覆盖 (./ai-lib-data/)
        if let Ok(cwd) = std::env::current_dir() {
            let cwd_data = cwd.join("ai-lib-data");
            if cwd_data.exists() {
                registry.merge_from_dir(&cwd_data)?;
            }
        }
        
        Ok(registry)
    }
    
    /// 编译时嵌入默认数据
    fn load_embedded(&mut self) -> Result<(), RegistryError> {
        // 嵌入的 JSON 数据 (编译时确定)
        const EMBEDDED_PROVIDERS: &str = include_str!("../../data/providers.json");
        const EMBEDDED_MODELS: &str = include_str!("../../data/models.json");
        
        let providers: Vec<ProviderDefinition> = serde_json::from_str(EMBEDDED_PROVIDERS)?;
        let models: Vec<ModelDefinition> = serde_json::from_str(EMBEDDED_MODELS)?;
        
        for p in providers {
            self.providers.insert(p.id.clone(), p);
        }
        for m in models {
            self.models.insert(m.id.clone(), m);
        }
        
        self.source = RegistrySource::Embedded;
        Ok(())
    }
}
```

### PRO 层实现（基于现有 config_hot_reload）

```rust
// ai-lib-pro/src/registry/hot_reload.rs

use crate::config_hot_reload::{ConfigHotReload, FileWatcherConfig, ValidatedConfigManager};

/// PRO 模型注册表 (支持热更新)
pub struct ProModelRegistry {
    /// 基础注册表
    base: Arc<RwLock<ModelRegistry>>,
    /// 热更新管理器
    hot_reload: Option<ConfigHotReload>,
    /// 远程同步器
    remote_syncer: Option<RemoteSyncer>,
    /// 配置验证器
    validator: ValidatedConfigManager,
}

impl ProModelRegistry {
    pub async fn new(config: ProRegistryConfig) -> Result<Self, RegistryError> {
        let base = Arc::new(RwLock::new(ModelRegistry::load()?));
        let validator = ValidatedConfigManager::new(5);  // 保留5个备份
        validator.add_validator(JsonValidator);
        validator.add_validator(SchemaValidator::new("model_registry.schema.json")?);
        
        let mut registry = Self {
            base,
            hot_reload: None,
            remote_syncer: None,
            validator,
        };
        
        // 启用文件热更新 (如果配置)
        if let Some(file_config) = config.file_watch {
            registry.enable_file_hot_reload(file_config).await?;
        }
        
        // 启用远程同步 (如果配置)
        if let Some(remote_config) = config.remote_sync {
            registry.enable_remote_sync(remote_config).await?;
        }
        
        Ok(registry)
    }
    
    /// 启用文件热更新
    async fn enable_file_hot_reload(&mut self, config: FileWatchConfig) -> Result<(), RegistryError> {
        let base = self.base.clone();
        let validator = self.validator.clone();
        
        let watcher_config = FileWatcherConfig {
            root: config.root.clone(),
            interval: config.interval,
        };
        
        let handle = ConfigHotReload::watch_enhanced(
            watcher_config,
            vec!["providers.json".to_string(), "models.json".to_string()],
            move |content| {
                // 验证 JSON 格式
                serde_json::from_str::<serde_json::Value>(content)
                    .map_err(|e| format!("Invalid JSON: {}", e))?;
                Ok(())
            },
            move || {
                // 热更新回调
                if let Ok(mut reg) = base.write() {
                    if let Err(e) = reg.reload_from_dir(&config.root) {
                        tracing::error!("Hot reload failed: {}", e);
                    } else {
                        tracing::info!("Model registry reloaded successfully");
                    }
                }
            },
        ).await;
        
        self.hot_reload = Some(handle);
        Ok(())
    }
    
    /// 启用远程配置同步
    async fn enable_remote_sync(&mut self, config: RemoteSyncConfig) -> Result<(), RegistryError> {
        let syncer = match config.backend {
            RemoteBackend::Consul { addr } => {
                RemoteSyncer::consul(addr).await?
            }
            RemoteBackend::Etcd { endpoints } => {
                RemoteSyncer::etcd(endpoints).await?
            }
            RemoteBackend::Http { url, interval } => {
                RemoteSyncer::http(url, interval).await?
            }
        };
        
        // 启动后台同步任务
        let base = self.base.clone();
        tokio::spawn(async move {
            syncer.run_sync_loop(base).await;
        });
        
        Ok(())
    }
}
```

---

## 三、数据文件格式设计

### Schema 定义

```json
// ai-lib/data/schema/model_definition.schema.json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://ailib.info/schemas/model_definition.json",
  "title": "Model Definition",
  "type": "object",
  "required": ["id", "provider", "primary_type", "capabilities"],
  "properties": {
    "id": {
      "type": "string",
      "description": "Unique model identifier"
    },
    "provider": {
      "type": "string",
      "description": "Provider ID (e.g., openai, anthropic)"
    },
    "display_name": {
      "type": "string"
    },
    "primary_type": {
      "type": "string",
      "enum": ["chat", "reasoning", "coding", "multimodal", "embedding"]
    },
    "capabilities": {
      "type": "array",
      "items": {
        "type": "string",
        "enum": [
          "text_input", "image_input", "audio_input", "video_input",
          "text_output", "image_output", "audio_output",
          "streaming", "function_call", "tool_use", "json_mode",
          "reasoning_trace", "long_context"
        ]
      }
    },
    "context_window": {
      "type": "integer",
      "minimum": 1
    },
    "max_output_tokens": {
      "type": "integer"
    },
    "pricing": {
      "type": "object",
      "properties": {
        "input_per_million": { "type": "number" },
        "output_per_million": { "type": "number" },
        "currency": { "type": "string", "default": "USD" }
      }
    },
    "performance_tier": {
      "type": "string",
      "enum": ["fast", "balanced", "quality"]
    },
    "status": {
      "type": "string",
      "enum": ["active", "preview", "deprecated", "legacy"]
    },
    "release_date": {
      "type": "string",
      "format": "date"
    },
    "knowledge_cutoff": {
      "type": "string"
    }
  }
}
```

### 示例数据文件

```json
// ai-lib/data/models/openai.json
{
  "$schema": "../schema/model_definition.schema.json",
  "version": "2024.12.08",
  "provider": "openai",
  "models": [
    {
      "id": "gpt-4o",
      "display_name": "GPT-4o",
      "primary_type": "multimodal",
      "capabilities": ["text_input", "image_input", "text_output", "streaming", "function_call", "json_mode"],
      "context_window": 128000,
      "max_output_tokens": 16384,
      "pricing": { "input_per_million": 2.50, "output_per_million": 10.00 },
      "performance_tier": "balanced",
      "status": "active",
      "release_date": "2024-05-13"
    },
    {
      "id": "o1",
      "display_name": "OpenAI o1",
      "primary_type": "reasoning",
      "capabilities": ["text_input", "text_output", "reasoning_trace", "long_context"],
      "context_window": 200000,
      "max_output_tokens": 100000,
      "pricing": { "input_per_million": 15.00, "output_per_million": 60.00 },
      "performance_tier": "quality",
      "status": "active",
      "release_date": "2024-12-05"
    },
    {
      "id": "o1-mini",
      "display_name": "OpenAI o1-mini",
      "primary_type": "reasoning",
      "capabilities": ["text_input", "text_output", "reasoning_trace"],
      "context_window": 128000,
      "max_output_tokens": 65536,
      "pricing": { "input_per_million": 3.00, "output_per_million": 12.00 },
      "performance_tier": "fast",
      "status": "active"
    }
  ],
  "defaults": {
    "chat": "gpt-4o-mini",
    "reasoning": "o1-mini",
    "multimodal": "gpt-4o",
    "embedding": "text-embedding-3-small"
  }
}
```

---

## 四、实施路线图（符合 model_resolver_pro_plan.md）

### 对齐现有规划的里程碑

| 阶段 | model_resolver_pro_plan | 本方案对应 | 预计时间 |
|------|-------------------------|------------|----------|
| **M1** | Externalized Model Registry | OSS: Schema设计 + 编译时嵌入 | 2周 |
| **M1** | Loader + hot-reload | PRO: 文件热更新 | 2周 |
| **M2** | Tenant-Specific Policies | PRO: 多租户策略层 | 3周 |
| **M3** | Observability & Health | PRO: 注册表健康监控 | 2周 |
| **M4** | Governance & Workflows | PRO: 审批 + 配额 | 4周 |

### 具体任务分解

```
Phase 1: OSS 基础 (2周)
├── 定义 ModelPrimaryType 枚举
├── 定义 ModelCapabilities bitflags
├── 设计 JSON Schema
├── 创建主要 Provider 数据文件
├── 实现 include_str! 嵌入机制
└── 本地文件覆盖支持

Phase 2: PRO 热更新 (2周)
├── 复用 config_hot_reload 模块
├── 实现 ProModelRegistry
├── 文件监视 + 验证 + 回滚
└── 集成测试

Phase 3: PRO 远程同步 (3周)
├── Consul/etcd 适配器
├── HTTP 远程拉取
├── 同步冲突解决策略
└── 多租户策略叠加

Phase 4: 数据维护自动化 (持续)
├── GitHub Action 定期检查 Provider 变更
├── 社区贡献流程 (PR → 验证 → 合并)
└── 版本发布自动化
```

---

## 总结

| 层级 | 特性 | 网络依赖 | 更新方式 |
|------|------|----------|----------|
| **ai-lib (OSS)** | 编译时嵌入 + 本地覆盖 | ❌ 无 | 库升级 或 手动放置文件 |
| **ai-lib-pro (Enterprise)** | 热更新 + 远程同步 | ✅ 可选 | 零停机 + 自动同步 |

**这样的分层设计确保：**
1. OSS 用户始终有可用的默认数据，无需网络
2. 企业用户可享受实时更新能力
3. 库版本与数据版本解耦，减少升级频率
4. 符合现有 `model_resolver_pro_plan.md` 的规划方向